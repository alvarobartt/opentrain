import warnings
from pathlib import Path
from typing import Union

import openai

from opentrain.utils import prepare_openai_dataset, validate_openai_dataset


class OpenAITrainer:
    """A class for training (fine-tuning) OpenAI models.

    Attributes:
        model: The model to fine-tune.
        fine_tune_id: The fine-tune ID.

    Example:
        >>> from opentrain import OpenAITrainer
        >>> trainer = OpenAITrainer()
        >>> trainer.train("training_data.jsonl")
        >>> trainer.track_training()
    """

    def __init__(self, model: str = "ada") -> None:
        """Initialize `OpenAITrainer`.

        Args:
            model: The model to fine-tune. Must be one of the following: ada, babbage,
                curie, davinci.
        """
        assert model in [
            "ada",
            "babbage",
            "curie",
            "davinci",
        ], "The model must be one of the following: ada, babbage, curie, davinci."
        self.model = model

    def train(
        self,
        path_or_buf: Union[str, Path, list],
        local_validation: bool = False,
        epochs: int = 10,
        batch_size: int = 32,
    ) -> str:
        """Train (fine-tune) an OpenAI model on a given dataset.

        Args:
            path_or_buf: The path to the training data, or a list of dictionaries
                containing the training data.
            local_validation: If True, validate the training data locally before
                uploading it to OpenAI. Defaults to False, which means that the
                data will be validated, but in OpenAI-side.
            epochs: The number of epochs to train the model for.
            batch_size: The batch size to use for training.

        Returns:
            The fine-tune ID.
        """
        # TODO(alvarobartt): create a `Dataset` class to handle the training data.
        if isinstance(path_or_buf, list):
            file_path = prepare_openai_dataset(path_or_buf)
        elif isinstance(path_or_buf, Path):
            file_path = path_or_buf.as_posix()
        else:
            file_path = path_or_buf

        if local_validation:
            assert validate_openai_dataset(file_path), (
                "The dataset is not valid, since it must contain only prompt-completion"
                " pairs."
            )

        # TODO(alvarobartt): one may want to use a previously uploaded file, so we
        #  should check if the file is already uploaded, and if so, then use it.
        upload_response = openai.File.create(
            file=open(file_path, "rb"),
            purpose="fine-tune",
        )
        file_id = upload_response.id
        fine_tune_response = openai.FineTune.create(
            training_file=file_id,
            model=self.model,
            n_epochs=epochs,
            batch_size=batch_size,
        )
        self.fine_tune_id = fine_tune_response.id
        warnings.warn(
            "Since the OpenAI API may take from minutes to hours depending on the size"
            " of the training data, then from now on, you'll be able to check its"
            " progress via the following command: `openai api fine_tunes.follow -i"
            f" {self.fine_tune_id}`. Once the training is completed, then you'll be"
            " able to use `OpenAIPredict` with the either the fine tune id returned,"
            " or from the model name generated by OpenAI linked to your account.",
            stacklevel=2,
        )
        return self.fine_tune_id

    def track_training(self) -> str:
        """Track the training progress of the model being fine-tuned.

        Returns:
            A string containing the training events.
        """
        if not self.fine_tune_id:
            raise ValueError("You must first train the model.")
        return openai.FineTune.stream_events(self.fine_tune_id)
